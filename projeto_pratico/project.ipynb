{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595560534163",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collection(filepath):\n",
    "\n",
    "    # lê o dataset\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # monta um dataframe com todas as features a porcentagem dos dados nulos\n",
    "    null_data = pd.DataFrame(data = [list(df.columns), list(df.isnull().sum())]).transpose()\n",
    "    null_data.columns = ['feature', 'null_data']\n",
    "\n",
    "    # filtra o dataframe para colunas com no máximo 50% dos dados ausentes\n",
    "    df = df.filter(items = null_data.feature.loc[null_data.null_data < 0.5 * df.shape[0]])\n",
    "\n",
    "    # exclui as colunas que não serão usadas na análise\n",
    "    df.drop(columns = ['Unnamed: 0', 'fl_matriz','natureza_juridica_macro','de_ramo','fl_spa', 'fl_antt',\n",
    "    'idade_empresa_anos','vl_total_veiculos_pesados_grupo','vl_total_veiculos_leves_grupo','fl_veiculo',\n",
    "    'fl_me','fl_sa','fl_epp','fl_mei','fl_ltda','dt_situacao','fl_st_especial','fl_email','fl_telefone',\n",
    "    'fl_rm','nm_divisao','fl_optante_simples','sg_uf_matriz','de_saude_tributaria','de_saude_rescencia',\n",
    "    'nu_meses_rescencia','fl_simples_irregular','empsetorcensitariofaixarendapopulacao','nm_meso_regiao',\n",
    "    'nm_micro_regiao','fl_passivel_iss','idade_media_socios','idade_maxima_socios','idade_minima_socios',\n",
    "    'qt_socios_st_regular','de_faixa_faturamento_estimado','vl_faturamento_estimado_grupo_aux',\n",
    "    'vl_faturamento_estimado_aux','qt_socios','qt_socios_pj','qt_socios_pf', 'qt_filiais'], axis = 1, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "\n",
    "    # todos os setores que estão nulos serão classificados na nova categoria OUTROS\n",
    "    df.setor.fillna('OUTROS', inplace = True)\n",
    "    # todos os segmentos que estão nulos serão classificados na nova categoria OUTROS\n",
    "    df.nm_segmento.fillna('OUTROS', inplace =  True)\n",
    "    # para os dados que estiverem com dado nulo será inserido a categoria que mais se repete\n",
    "    df.de_faixa_faturamento_estimado_grupo.fillna(df.de_faixa_faturamento_estimado_grupo.mode().values[0], inplace = True)\n",
    "    # para os dados que estiverem com dado nulo será inserido a categoria que mais se repete, porém será realizado um group \n",
    "    # by a partir do nível de ativade da empresa\n",
    "    faixa_faturamento_por_nivel = df.groupby(['de_faixa_faturamento_estimado_grupo'])['de_nivel_atividade'].agg(pd.Series.mode)\n",
    "    df.de_nivel_atividade.fillna(df.de_faixa_faturamento_estimado_grupo.map(faixa_faturamento_por_nivel), inplace = True)\n",
    "\n",
    "    # realiza o filtro para selecionar somente as features que serão utilizadas no modelo\n",
    "    df = df.filter(items = ['id','de_natureza_juridica','sg_uf', 'setor', 'nm_segmento', 'idade_emp_cat','de_nivel_atividade',\n",
    "    'de_faixa_faturamento_estimado_grupo'])\n",
    "\n",
    "    # transforma as variáveis categóricas em variáveis discretas\n",
    "    labelencoder = LabelEncoder()\n",
    "    df.de_natureza_juridica = labelencoder.fit_transform(df.de_natureza_juridica)\n",
    "    df.sg_uf = labelencoder.fit_transform(df.sg_uf)\n",
    "    df.setor = labelencoder.fit_transform(df.setor)\n",
    "    df.nm_segmento = labelencoder.fit_transform(df.nm_segmento)\n",
    "    df.idade_emp_cat = labelencoder.fit_transform(df.idade_emp_cat)\n",
    "    df.de_nivel_atividade = labelencoder.fit_transform(df.de_nivel_atividade)\n",
    "    df.de_faixa_faturamento_estimado_grupo = labelencoder.fit_transform(df.de_faixa_faturamento_estimado_grupo)\n",
    "\n",
    "    # padroniza os dados na mesma escala\n",
    "    scaler = StandardScaler()\n",
    "    ids = df.id\n",
    "    features = df.filter(items = ['de_natureza_juridica','sg_uf', 'setor', 'nm_segmento', 'idade_emp_cat','de_nivel_atividade',\n",
    "    'de_faixa_faturamento_estimado_grupo'])\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    # redução de dimensionalidade utilizando método PCA - Análise das Componentes Principais\n",
    "    pca = PCA(n_components= 3)\n",
    "    features = pca.fit_transform(features)\n",
    "\n",
    "    return df, ids, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features):\n",
    "    # gera o modelo de KMeans\n",
    "    kmeans = KMeans(n_clusters= 6, init = 'k-means++')\n",
    "    # treina o modelo\n",
    "    kmeans.fit(features)\n",
    "    # pega os valores dos centróides\n",
    "    centroides = kmeans.cluster_centers_\n",
    "    # pega as distancias para o centróides\n",
    "    distancia = kmeans.fit_transform(features)\n",
    "    # pega o agrupamento de cada id\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    return  kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(kmeans, features):\n",
    "    output = kmeans.predict(features)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_collection('../../estaticos_market.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, ids, features = data_preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0.20384123, -0.7561203 , -1.291459  ])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "features[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "kmeans.labels_[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0])"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "output = predict(kmeans, [[0.5, 1.87, -1.28]])\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(x = features[:,0], y =features[:,1], z = features[:,2], color = labels)\n",
    "fig.show()"
   ]
  }
 ]
}